{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2b0165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "sys.path.append('../../7_Classification/BehaviourClassification/DeepLearning/dl-4-tsc-master')\n",
    "\n",
    "from holsteinlib import windowing, functions\n",
    "from holsteinlib.evaluation_v2 import evaluate_model\n",
    "\n",
    "# MiniRocket\n",
    "from sktime.transformations.panel.rocket import MiniRocketMultivariateVariable\n",
    "\n",
    "# DL\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09bffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_class_data(data_dict, keys = ['accX', 'accY', 'accZ'], trim=0):\n",
    "    \n",
    "    def trim_data(data):\n",
    "        trimmed_data = [data[key][:trim] if trim > 0 else data[key] for key in keys]\n",
    "#         return np.hstack(trimmed_data)\n",
    "        return trimmed_data\n",
    "    \n",
    "    X = [trim_data(data) for _, data_set in data_dict.items() for data in data_set]\n",
    "    y = [label for label, data_set in data_dict.items() for _ in data_set]\n",
    " \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2256747",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger:\n",
    "    def __init__(self, filepath):\n",
    "        self.file = open(filepath, 'w')\n",
    "        self.terminal = sys.stdout\n",
    "\n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.file.write(message)\n",
    "\n",
    "    def flush(self):\n",
    "        pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a4ab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './WISDM_Dataset/WISDM_at_v2.0_raw.txt'\n",
    "\n",
    "column_names = ['series', 'label', 'timestamp', 'accX', 'accY', 'accZ']\n",
    "\n",
    "dtype = {\n",
    "    'user': int,\n",
    "    'activity': str,\n",
    "    'timestamp': int,\n",
    "    'accX': float,\n",
    "    'accY': float,\n",
    "    'accZ': float\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdb947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = sorted(['drinking_milk', 'grooming', 'lying', 'other', 'running', 'walking'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d84a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.read_csv(dataset_path, sep=',', lineterminator=';', names=column_names, \n",
    "                         skip_blank_lines=True, on_bad_lines='skip', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7defed",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f61a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \\n characters from user column and convert to integer\n",
    "dataset_df['user'] = dataset_df['user'].str.replace('\\n', '').replace('', np.nan).astype('Int64')\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "dataset_df['timestamp'] = pd.to_datetime(dataset_df['timestamp'], errors='coerce', unit='ms')\n",
    "\n",
    "# Convert accX, accY, accZ to float and handle conversion errors\n",
    "dataset_df['accX'] = pd.to_numeric(dataset_df['accX'], errors='coerce')\n",
    "dataset_df['accY'] = pd.to_numeric(dataset_df['accY'], errors='coerce')\n",
    "dataset_df['accZ'] = pd.to_numeric(dataset_df['accZ'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in any of the specified columns\n",
    "dataset_df.dropna(subset=['user', 'timestamp', 'accX', 'accY', 'accZ'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800ea5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0c74d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.to_csv('../../7_Classification/BehaviourClassification/Transformers/ConvTran-main/Dataset/Segmentation/ActivityRecognition/ActivityRecognition.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9656957a",
   "metadata": {},
   "source": [
    "# windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c2df37",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = dataset_df.user.unique()\n",
    "\n",
    "# windowing params\n",
    "window_duration = 3\n",
    "data_frequency = 20\n",
    "min_window_size = 0.95\n",
    "overlap = 0.5\n",
    "datetime_column_name = 'timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a32c60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "window_dataset = {}\n",
    "for user in user_ids:\n",
    "    window_dataset[user] = {}\n",
    "    \n",
    "    user_df = dataset_df[dataset_df.user == user]\n",
    "    \n",
    "    labels = user_df.activity.unique()\n",
    "    \n",
    "    for label in labels:\n",
    "        window_dataset[user][label] = []\n",
    "        \n",
    "        label_df = user_df[user_df.activity == label]\n",
    "        \n",
    "        windows = windowing.return_windows(label_df, \n",
    "                                           window_duration=window_duration, \n",
    "                                           data_frequency=data_frequency, \n",
    "                                           min_window_size=min_window_size, \n",
    "                                           overlap=overlap, \n",
    "                                           datetime_column_name=datetime_column_name)\n",
    "        \n",
    "        window_dataset[user][label].extend(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0912e282",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('WISDM_window_dataset_v1.pickle', 'wb') as handle:\n",
    "    pickle.dump(window_dataset, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5119b55d",
   "metadata": {},
   "source": [
    "# Deep Learning Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005e367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data_dict, max_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for subject_id, labels_dict in data_dict.items():\n",
    "        for label, df_list in labels_dict.items():\n",
    "            for df in df_list:\n",
    "                features = df[['accX', 'accY', 'accZ']].values\n",
    "                \n",
    "                X.append(features)\n",
    "                y.append(label)\n",
    "                \n",
    "    # Pad sequences to ensure they have the same length\n",
    "    X = pad_sequences(X, maxlen=max_length, dtype='float32', padding='post', truncating='post')\n",
    "    \n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Standardize the feature data\n",
    "    num_features = X.shape[2]\n",
    "    # Reshape X to 2D array for standardization (ignoring padding)\n",
    "    X_reshaped = X.reshape(-1, num_features)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_reshaped)\n",
    "\n",
    "    X = X_scaled.reshape(-1, max_length, num_features)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe46f5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 60 # 20Hz\n",
    "X_processed, y_processed = preprocess_data(window_dataset, max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfb4a94",
   "metadata": {},
   "source": [
    "# Train, Validation, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aae547",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_processed, y_processed, test_size=0.33, \n",
    "                                                    stratify=y_processed, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9332b9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.33, \n",
    "                                                    stratify=y_train_val, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a33353a",
   "metadata": {},
   "source": [
    "# Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eea303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode string labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "nb_classes = len(np.unique(y_train))\n",
    "y_train_one_hot = to_categorical(y_train_encoded, nb_classes)\n",
    "y_val_one_hot = to_categorical(y_val_encoded, nb_classes)\n",
    "y_test_one_hot = to_categorical(y_test_encoded, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb395c4",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5409d5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifiers.mlp import Classifier_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ae3863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory\n",
    "output_directory = 'DL_Results/mlp/'\n",
    "\n",
    "# Create the model\n",
    "input_shape = X_train.shape[1:]  # Input shape for the MLP model\n",
    "verbose = True\n",
    "\n",
    "classifier = Classifier_MLP(output_directory, input_shape, nb_classes, verbose=verbose)\n",
    "\n",
    "# Train the model\n",
    "classifier.fit(X_train, y_train_one_hot, X_val, y_val_one_hot, y_val_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f77216",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics, mlp_y_pred = classifier.predict(X_test, y_test_encoded, X_train, y_train_one_hot, y_test_one_hot)\n",
    "\n",
    "df_metrics.to_csv(output_directory + 'df_metrics.csv')\n",
    "\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021ffa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_original = label_encoder.inverse_transform(mlp_y_pred)\n",
    "\n",
    "class_wise_metrics, overall_report, additional_metrics, cm = evaluate_model(y_test, y_pred_original, class_labels)\n",
    "\n",
    "all_results = {\n",
    "    'class_wise_metrics' : class_wise_metrics,\n",
    "    'overall_report' : overall_report,\n",
    "    'additional_metrics' : additional_metrics,\n",
    "    'confusion_matirx': cm\n",
    "}\n",
    "\n",
    "with open(output_directory + 'all_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9280adbd",
   "metadata": {},
   "source": [
    "# FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b945fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifiers.fcn import Classifier_FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57ac0c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the output directory\n",
    "output_directory = 'DL_Results/fcn/'\n",
    "\n",
    "# Create the model\n",
    "input_shape = X_train.shape[1:]  # Input shape for the MLP model\n",
    "verbose = True\n",
    "\n",
    "classifier = Classifier_FCN(output_directory, input_shape, nb_classes, verbose=verbose)\n",
    "\n",
    "# Train the model\n",
    "classifier.fit(X_train, y_train_one_hot, X_val, y_val_one_hot, y_val_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3713c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics, fcn_y_pred = classifier.predict(X_test, y_test_encoded, X_train, y_train_one_hot, y_test_one_hot)\n",
    "\n",
    "df_metrics.to_csv(output_directory + 'df_metrics.csv')\n",
    "\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef13435",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_original = label_encoder.inverse_transform(fcn_y_pred)\n",
    "\n",
    "class_wise_metrics, overall_report, additional_metrics, cm = evaluate_model(y_test, y_pred_original, class_labels)\n",
    "\n",
    "all_results = {\n",
    "    'class_wise_metrics' : class_wise_metrics,\n",
    "    'overall_report' : overall_report,\n",
    "    'additional_metrics' : additional_metrics,\n",
    "    'confusion_matirx': cm\n",
    "}\n",
    "\n",
    "with open(output_directory + 'all_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc57cd6",
   "metadata": {},
   "source": [
    "# RESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4917c13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifiers.resnet import Classifier_RESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf69e9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory\n",
    "output_directory = 'DL_Results/resnet/'\n",
    "\n",
    "# Create the model\n",
    "input_shape = X_train.shape[1:]  # Input shape for the MLP model\n",
    "verbose = True\n",
    "\n",
    "classifier = Classifier_RESNET(output_directory, input_shape, nb_classes, verbose=verbose)\n",
    "\n",
    "# Train the model\n",
    "classifier.fit(X_train, y_train_one_hot, X_val, y_val_one_hot, y_val_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9499506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics, resnet_y_pred = classifier.predict(X_test, y_test_encoded, X_train, y_train_one_hot, y_test_one_hot)\n",
    "\n",
    "df_metrics.to_csv(output_directory + 'df_metrics.csv')\n",
    "\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f5fe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_original = label_encoder.inverse_transform(resnet_y_pred)\n",
    "\n",
    "class_wise_metrics, overall_report, additional_metrics, cm = evaluate_model(y_test, y_pred_original, class_labels)\n",
    "\n",
    "all_results = {\n",
    "    'class_wise_metrics' : class_wise_metrics,\n",
    "    'overall_report' : overall_report,\n",
    "    'additional_metrics' : additional_metrics,\n",
    "    'confusion_matirx': cm\n",
    "}\n",
    "\n",
    "with open(output_directory + 'all_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccb6192",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bb1034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifiers.encoder import Classifier_ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490132ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the output directory\n",
    "output_directory = 'DL_Results/encoder/'\n",
    "\n",
    "log_filepath = os.path.join(output_directory, 'training_log.txt')\n",
    "\n",
    "# Create the model\n",
    "input_shape = X_train.shape[1:]  # Input shape for the MLP model\n",
    "verbose = True\n",
    "\n",
    "# Redirect verbose output to the file\n",
    "sys.stdout = Logger(log_filepath)\n",
    "\n",
    "classifier = Classifier_ENCODER(output_directory, input_shape, nb_classes, verbose=verbose)\n",
    "\n",
    "# Train the model\n",
    "classifier.fit(X_train, y_train_one_hot, X_val, y_val_one_hot, y_val_encoded)\n",
    "\n",
    "# Reset stdout to its original value\n",
    "sys.stdout = sys.stdout.terminal\n",
    "\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8954df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics, encoder_y_pred = classifier.predict(X_test, y_test_encoded, X_train, y_train_one_hot, y_test_one_hot)\n",
    "\n",
    "df_metrics.to_csv(output_directory + 'df_metrics.csv')\n",
    "\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a097e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_original = label_encoder.inverse_transform(encoder_y_pred)\n",
    "\n",
    "class_wise_metrics, overall_report, additional_metrics, cm = evaluate_model(y_test, y_pred_original, class_labels)\n",
    "\n",
    "all_results = {\n",
    "    'class_wise_metrics' : class_wise_metrics,\n",
    "    'overall_report' : overall_report,\n",
    "    'additional_metrics' : additional_metrics,\n",
    "    'confusion_matirx': cm\n",
    "}\n",
    "\n",
    "with open(output_directory + 'all_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ec9618",
   "metadata": {},
   "source": [
    "# MCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccce9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifiers.mcnn import Classifier_MCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dced937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory\n",
    "output_directory = 'DL_Results/mcnn/'\n",
    "\n",
    "# Create the model\n",
    "input_shape = X_train.shape[1:]  # Input shape for the MLP model\n",
    "verbose = True\n",
    "\n",
    "classifier = Classifier_MCNN(output_directory=output_directory, verbose=verbose)\n",
    "\n",
    "# Train the model\n",
    "classifier.fit(X_train, y_train_one_hot, X_test, y_test_one_hot, y_test_encoded, X_val, y_val_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fb0baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics, mcnn_y_pred = classifier.predict(X_test, y_test_encoded, X_train, y_train_one_hot, y_test_one_hot,\n",
    "                                            X_val, y_val_one_hot)\n",
    "\n",
    "df_metrics.to_csv(output_directory + 'df_metrics.csv')\n",
    "\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ec2406",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_original = label_encoder.inverse_transform(mcnn_y_pred)\n",
    "\n",
    "class_wise_metrics, overall_report, additional_metrics, cm = evaluate_model(y_test, y_pred_original, class_labels)\n",
    "\n",
    "all_results = {\n",
    "    'class_wise_metrics' : class_wise_metrics,\n",
    "    'overall_report' : overall_report,\n",
    "    'additional_metrics' : additional_metrics,\n",
    "    'confusion_matirx': cm\n",
    "}\n",
    "\n",
    "with open(output_directory + 'all_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f3d403",
   "metadata": {},
   "source": [
    "# t-LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6cd31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifiers.tlenet import Classifier_TLENET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d80bf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory\n",
    "output_directory = 'DL_Results/tlenet/'\n",
    "\n",
    "# Create the model\n",
    "input_shape = X_train.shape[1:]  # Input shape for the MLP model\n",
    "verbose = True\n",
    "\n",
    "classifier = Classifier_TLENET(output_directory, verbose=verbose)\n",
    "\n",
    "# Train the model\n",
    "classifier.fit(X_train, y_train_one_hot, X_test, y_test_one_hot, y_test_encoded, X_val, y_val_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb90285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics, tlenet_y_pred = classifier.predict(X_test, y_test_encoded, X_train, y_train_one_hot, y_test_one_hot)\n",
    "\n",
    "df_metrics.to_csv(output_directory + 'df_metrics.csv')\n",
    "\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a95f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_original = label_encoder.inverse_transform(tlenet_y_pred)\n",
    "\n",
    "class_wise_metrics, overall_report, additional_metrics, cm = evaluate_model(y_test, y_pred_original, class_labels)\n",
    "\n",
    "all_results = {\n",
    "    'class_wise_metrics' : class_wise_metrics,\n",
    "    'overall_report' : overall_report,\n",
    "    'additional_metrics' : additional_metrics,\n",
    "    'confusion_matirx': cm\n",
    "}\n",
    "\n",
    "with open(output_directory + 'all_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342dc00b",
   "metadata": {},
   "source": [
    "# MCDCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4f346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifiers.mcdcnn import Classifier_MCDCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9c5c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory\n",
    "output_directory = 'DL_Results/mcdcnn/'\n",
    "\n",
    "# Create the model\n",
    "input_shape = X_train.shape[1:]  # Input shape for the MLP model\n",
    "verbose = True\n",
    "\n",
    "classifier = Classifier_MCDCNN(output_directory, input_shape, nb_classes, verbose=verbose)\n",
    "\n",
    "# Train the model\n",
    "classifier.fit(X_train, y_train_one_hot, X_test, y_test_one_hot, y_test_encoded, X_val, y_val_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4ed160",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics, mcdcnn_y_pred = classifier.predict(X_test, y_test_encoded, X_train, y_train_one_hot, y_test_one_hot)\n",
    "\n",
    "df_metrics.to_csv(output_directory + 'df_metrics.csv')\n",
    "\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975a03b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_original = label_encoder.inverse_transform(mcdcnn_y_pred)\n",
    "\n",
    "class_wise_metrics, overall_report, additional_metrics, cm = evaluate_model(y_test, y_pred_original, class_labels)\n",
    "\n",
    "all_results = {\n",
    "    'class_wise_metrics' : class_wise_metrics,\n",
    "    'overall_report' : overall_report,\n",
    "    'additional_metrics' : additional_metrics,\n",
    "    'confusion_matirx': cm\n",
    "}\n",
    "\n",
    "with open(output_directory + 'all_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4312c9a4",
   "metadata": {},
   "source": [
    "# TWIESEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e476fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifiers.twiesn import Classifier_TWIESN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d9b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory\n",
    "output_directory = 'DL_Results/twiesen/'\n",
    "\n",
    "# Create the model\n",
    "input_shape = X_train.shape[1:]  # Input shape for the MLP model\n",
    "verbose = True\n",
    "\n",
    "classifier = Classifier_TWIESN(output_directory=output_directory, verbose=True)\n",
    "\n",
    "# Train the model\n",
    "classifier.fit(X_train, y_train_one_hot, X_test, y_test_one_hot, y_test_encoded, X_val, y_val_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b36581b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics, train_acc, twiesen_y_pred = classifier.train()\n",
    "\n",
    "df_metrics.to_csv(output_directory + 'df_metrics.csv')\n",
    "\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8789a009",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_original = label_encoder.inverse_transform(twiesen_y_pred)\n",
    "\n",
    "class_wise_metrics, overall_report, additional_metrics, cm = evaluate_model(y_test, y_pred_original, class_labels)\n",
    "\n",
    "all_results = {\n",
    "    'class_wise_metrics' : class_wise_metrics,\n",
    "    'overall_report' : overall_report,\n",
    "    'additional_metrics' : additional_metrics,\n",
    "    'confusion_matirx': cm\n",
    "}\n",
    "\n",
    "with open(output_directory + 'all_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a8266e",
   "metadata": {},
   "source": [
    "# Time-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1633b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifiers.cnn import Classifier_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d72dd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory\n",
    "output_directory = 'DL_Results/cnn/'\n",
    "\n",
    "# Create the model\n",
    "input_shape = X_train.shape[1:]  # Input shape for the MLP model\n",
    "verbose = True\n",
    "\n",
    "classifier = Classifier_CNN(output_directory, input_shape, nb_classes, verbose=verbose)\n",
    "\n",
    "# Train the model\n",
    "classifier.fit(X_train, y_train_one_hot, X_val, y_val_one_hot, y_val_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521917ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics, cnn_y_pred = classifier.predict(X_test, y_test_encoded, X_train, y_train_one_hot, y_test_one_hot)\n",
    "\n",
    "df_metrics.to_csv(output_directory + 'df_metrics.csv')\n",
    "\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c4b502",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_original = label_encoder.inverse_transform(cnn_y_pred)\n",
    "\n",
    "class_wise_metrics, overall_report, additional_metrics, cm = evaluate_model(y_test, y_pred_original, class_labels)\n",
    "\n",
    "all_results = {\n",
    "    'class_wise_metrics' : class_wise_metrics,\n",
    "    'overall_report' : overall_report,\n",
    "    'additional_metrics' : additional_metrics,\n",
    "    'confusion_matirx': cm\n",
    "}\n",
    "\n",
    "with open(output_directory + 'all_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7975417",
   "metadata": {},
   "source": [
    "# Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080ddf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifiers.inception import Classifier_INCEPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9c65b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory\n",
    "output_directory = 'DL_Results/inception/'\n",
    "\n",
    "# Create the model\n",
    "input_shape = X_train.shape[1:]  # Input shape for the MLP model\n",
    "verbose = True\n",
    "\n",
    "classifier = Classifier_INCEPTION(output_directory, input_shape, nb_classes, verbose=verbose)\n",
    "\n",
    "# Train the model\n",
    "classifier.fit(X_train, y_train_one_hot, X_val, y_val_one_hot, y_val_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd10ddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics, inception_y_pred = classifier.predict(X_test, y_test_encoded, X_train, y_train_one_hot, y_test_one_hot)\n",
    "\n",
    "df_metrics.to_csv(output_directory + 'df_metrics.csv')\n",
    "\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b61b349",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_original = label_encoder.inverse_transform(inception_y_pred)\n",
    "\n",
    "class_wise_metrics, overall_report, additional_metrics, cm = evaluate_model(y_test, y_pred_original, class_labels)\n",
    "\n",
    "all_results = {\n",
    "    'class_wise_metrics' : class_wise_metrics,\n",
    "    'overall_report' : overall_report,\n",
    "    'additional_metrics' : additional_metrics,\n",
    "    'confusion_matirx': cm\n",
    "}\n",
    "\n",
    "with open(output_directory + 'all_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f868d2bd",
   "metadata": {},
   "source": [
    "# ConvTran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1cc46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../7_Classification/BehaviourClassification/Transformers/ConvTran-main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf11da4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the arguments as if they are coming from the command line\n",
    "sys.argv = [\n",
    "    'main.py',\n",
    "    '--data_path', 'Dataset/Wisdm/',\n",
    "    '--output_dir', '../../../../8_Evaluation/Baseline_Evaluation/ConvTran_Results/',\n",
    "    '--Norm', 'False',\n",
    "    '--val_ratio', '0.2',\n",
    "    '--print_interval', '10',\n",
    "    '--Net_Type', 'C-T',\n",
    "    '--emb_size', '16',\n",
    "    '--dim_ff', '256',\n",
    "    '--num_heads', '8',\n",
    "    '--Fix_pos_encode', 'tAPE',\n",
    "    '--Rel_pos_encode', 'eRPE',\n",
    "    '--epochs', '100',\n",
    "    '--batch_size', '16',\n",
    "    '--lr', '1e-3',\n",
    "    '--dropout', '0.01',\n",
    "    '--val_interval', '2',\n",
    "    '--key_metric', 'accuracy',\n",
    "    '--gpu', '0',\n",
    "    '--seed', '1234'\n",
    "]\n",
    "\n",
    "# Run the script\n",
    "%run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbe43e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../../../8_Evaluation/Baseline_Evaluation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2bc908",
   "metadata": {},
   "source": [
    "# ROCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a18db05",
   "metadata": {},
   "source": [
    "## ROCKET feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038fcda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(X)\n",
    "\n",
    "trf = MiniRocketMultivariateVariable(num_kernels=10000) \n",
    "trf.fit(X_df) \n",
    "X_features = trf.transform(X_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6838780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_Rocket_features', X_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07af619",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502afdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ROCKET_train_val, X_ROCKET_test, y_ROCKET_train_val, y_ROCKET_test = train_test_split(X_features, y_processed, test_size=0.33, \n",
    "                                                    stratify=y_processed, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a9b48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge_clf = RidgeClassifierCV(**random_search.best_params_)\n",
    "ridge_clf = RidgeClassifierCV(fit_intercept= False, class_weight= 'balanced', alphas= 131.31400000000002)\n",
    "\n",
    "ridge_clf.fit(X_ROCKET_train_val, y_ROCKET_train_val)\n",
    "\n",
    "y_pre = ridge_clf.predict(X_ROCKET_test)\n",
    "\n",
    "print('Balanced Accuracy: ', balanced_accuracy_score(y_ROCKET_test, y_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb06bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_wise_metrics, overall_report, additional_metrics, cm = evaluate_model(y_ROCKET_test, y_pre, class_labels)\n",
    "\n",
    "all_results = {\n",
    "    'class_wise_metrics' : class_wise_metrics,\n",
    "    'overall_report' : overall_report,\n",
    "    'additional_metrics' : additional_metrics,\n",
    "    'confusion_matirx': cm\n",
    "}\n",
    "\n",
    "with open('ROCKET_results/all_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e2ce14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555cc5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
